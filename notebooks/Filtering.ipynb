{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This module contains code for filtering the data parsed with java parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gatherig all data in one table, removing duplicate imports and java.lang imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of compilation units inside java.lang package that should be ignored when loadig the data\n",
    "java_lang = {\"Appendable\", \"AutoCloseable\", \"CharSequence\", \"Cloneable\", \"Comparable\", \"Iterable\", \"Readable\", \n",
    "             \"Runnable\", \"Boolean\", \"Byte\", \"Character\", \"Class\", \"ClassLoader\", \"ClassValue\", \"Compiler\", \"Double\", \n",
    "             \"Enum\", \"Float\", \"InheritableThreadLocal\", \"Integer\", \"Long\", \"Math\", \"Number\", \"Object\", \"Package\", \n",
    "             \"Process\", \"ProcessBuilder\", \"Runtime\", \"RuntimePermission\", \"SecurityManager\", \"Short\", \n",
    "             \"StackTraceElement\", \"StrictMath\", \"String\", \"StringBuffer\", \"StringBuilder\", \"System\", \"Thread\", \n",
    "             \"ThreadGroup\", \"ThreadLocal\", \"Throwable\", \"Void\", \"ArithmeticException\", \n",
    "             \"ArrayIndexOutOfBoundsException\", \"ArrayStoreException\", \"ClassCastException\", \"ClassNotFoundException\", \n",
    "             \"CloneNotSupportedException\", \"EnumConstantNotPresentException\", \"Exception\", \"IllegalAccessException\", \n",
    "             \"IllegalArgumentException\", \"IllegalMonitorStateException\", \"IllegalStateException\", \n",
    "             \"IllegalThreadStateException\", \"IndexOutOfBoundsException\", \"InstantiationException\", \n",
    "             \"InterruptedException\", \"NegativeArraySizeException\", \"NoSuchFieldException\", \"NoSuchMethodException\", \n",
    "             \"NullPointerException\", \"NumberFormatException\", \"ReflectiveOperationException\", \"RuntimeException\", \n",
    "             \"SecurityException\", \"StringIndexOutOfBoundsException\", \"TypeNotPresentException\", \n",
    "             \"UnsupportedOperationException\", \"AbstractMethodError\", \"AssertionError\", \"BootstrapMethodError\", \n",
    "             \"ClassCircularityError\", \"ClassFormatError\", \"Error\", \"ExceptionInInitializerError\", \"IllegalAccessError\",\n",
    "             \"IncompatibleClassChangeError\", \"InstantiationError\", \"InternalError\", \"LinkageError\", \n",
    "             \"NoClassDefFoundError\", \"NoSuchFieldError\", \"NoSuchMethodError\", \"OutOfMemoryError\", \"StackOverflowError\",\n",
    "             \"ThreadDeath\", \"UnknownError\", \"UnsatisfiedLinkError\", \"UnsupportedClassVersionError\", \"VerifyError\", \n",
    "             \"VirtualMachineError\", \"Deprecated\", \"Override\", \"SafeVarargs\", \"SuppressWarnings\"}\n",
    "java_lang = {\"java.lang.\" + x for x in java_lang}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeDuplicateImports(imports):\n",
    "    \"\"\"\n",
    "    Get a list of strings (imports), remove all duplicates, and return a set of strings (unique imports). \n",
    "    \"\"\"\n",
    "    unique_imports = []\n",
    "    for clazz in imports:\n",
    "        if '.' not in clazz or clazz in java_lang:\n",
    "            continue\n",
    "        unique_imports.append(clazz)\n",
    "    return unique_imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join all data into one table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=91.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "JSON_FILES = sorted(glob('../data/GitHubNewOriginalParsed/*.json'))\n",
    "\n",
    "df = []\n",
    "for filename in tqdm(JSON_FILES):\n",
    "    tmp = pd.read_json(filename, lines=True)\n",
    "    tmp.classImports = tmp.classImports.apply(removeDuplicateImports)\n",
    "    df.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"repo\", inplace=True)  # sorting by repository makes later preprocessing steps easier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing repositories that do not define packages. This is paramount to filtering out duplicates in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repos(df, bad_repos):\n",
    "    print(\"Total repos: %d, total files: %d, repos to be removed: %d\" \n",
    "      %(len(df.repo.unique()), len(df), len(bad_repos)))\n",
    "    df = df[~df.repo.isin(bad_repos)]\n",
    "    print(\"Total repos: %d, total files: %d\" %(len(df.repo.unique()), len(df)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total repos: 43048, total files: 8410676, repos to be removed: 6483\n",
      "Total repos: 36565, total files: 4342539\n"
     ]
    }
   ],
   "source": [
    "bad_repos = []\n",
    "for i in range(len(df)):\n",
    "    if df.package.values[i] == \"\":\n",
    "        bad_repos.append(df.repo.values[i])\n",
    "bad_repos = set(bad_repos)\n",
    "df = remove_repos(df, bad_repos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing repos with duplicate packages. If there are two repositories with the same packages, the one that has been forked most is kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "forks = pd.read_json(\"../data/forks.json\", lines=True)\n",
    "# stars = pd.read_json(\"../data/stars.json\", lines=True)\n",
    "forks = dict(zip(forks.original, forks.f0_))\n",
    "# stars = dict(zip(stars.repo, forks.f0_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4342539.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "packages = {} # dictionary of the kind package_name -> list of repository names\n",
    "for i in tqdm(range(len(df))):\n",
    "    if df.package.values[i] in packages:\n",
    "        if df.repo.values[i] not in packages[df.package.values[i]]:\n",
    "            packages[df.package.values[i]].append(df.repo.values[i])\n",
    "    else:\n",
    "        packages[df.package.values[i]] = [df.repo.values[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=578057.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bad_repos = {\"\",} # set of repositories to be removed\n",
    "for package in tqdm(packages.keys()):\n",
    "    # list of repositories with the same package: Only one is kept in the end\n",
    "    repos_tmp = [x for x in packages[package] if x not in bad_repos]\n",
    "    if len(repos_tmp) <= 1:\n",
    "        continue\n",
    "    best_repo = repos_tmp[0]\n",
    "    max_forks = forks[repos_tmp[0]]\n",
    "    for repo in repos_tmp:  # search for the most forked repository among potential candidates for removal and keep it\n",
    "        if forks[repo] >= max_forks:\n",
    "            bad_repos.add(best_repo)\n",
    "            max_forks = forks[repo]\n",
    "            best_repo = repo\n",
    "        else:\n",
    "            bad_repos.add(repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total repos: 36565, total files: 4342539, repos to be removed: 8997\n",
      "Total repos: 27569, total files: 2542734\n"
     ]
    }
   ],
   "source": [
    "df= remove_repos(df, bad_repos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing repos that contain duplicate files. Keeping these repository messes up graph creation process in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2542734), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "first = 0\n",
    "curr_classes = []\n",
    "duplicate_repos = {\"\", } # repositories to be removed\n",
    "\n",
    "for i in tqdm(range(first, len(df))):\n",
    "    curr_classes.append(df.package.values[i] + '.' + df.name.values[i])\n",
    "    if first == i:\n",
    "        curr_repo = df.repo.values[first]\n",
    "    if (i == len(df) - 1) or (df.repo.values[i+1] != curr_repo):\n",
    "        # if the number of classes does not equal the number of unique classes\n",
    "        if len(set(curr_classes)) != len(curr_classes): \n",
    "            duplicate_repos.add(curr_repo)\n",
    "        first = i + 1\n",
    "        curr_classes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total repos: 27569, total files: 2542734, repos to be removed: 2109\n",
      "Total repos: 25461, total files: 2106230\n"
     ]
    }
   ],
   "source": [
    "df = remove_repos(df, duplicate_repos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('../data/all_data_new.json', lines=True, orient=\"records\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}