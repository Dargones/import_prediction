{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook contains code to generate baselines for the import prediction problem that the newural network results could later be compared to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import networkx as nx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different number of negatives a classifier is given. For Target size of 1, the problem becomes a binary\n",
    "# classifiecation problem (one positive, one negative). In other cases, this is a multiclass classification\n",
    "TARGET_SIZES = (1, 4, 24, 124)\n",
    "EMBED_SIZE = 10 # Embedding size used\n",
    "# keys for different features described below\n",
    "FEATURES = (\"ed_\", \"emb_self_\", \"emb_imp_\", \"degree_\", \"min_dist_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = joblib.load(\"../data/graphsTest\")\n",
    "train = joblib.load(\"../data/graphsTrain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating various features to be used in baseline prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (i) Edit distance between compilation unit names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from Wikipedia\n",
    "def levenshtein(s1, s2):\n",
    "    \"\"\"\n",
    "    Function to calculate edit distance between to strings. Copied from wikipedia\n",
    "    \"\"\"\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein(s2, s1)\n",
    "\n",
    "    # len(s1) >= len(s2)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1 # j+1 instead of j since previous_row and current_row are one character longer\n",
    "            deletions = current_row[j] + 1       # than s2\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    \n",
    "    return previous_row[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_edit_distance(graph):\n",
    "    \"\"\"\n",
    "    For each datapoint in the dataset calculate the edit distance between relevant pairs of nodes\n",
    "    :param graph:   a dictionary of the following form: \n",
    "                    \"annotations\" - initial node embeddings. These are composed of two parts. The first one\n",
    "                    encodes the class name, the second part record external imports in that class\\compilation unit\n",
    "                    \"edges\"   - a list of tuples of three elements each (source, edge_type, destination)\n",
    "                    \"strings\" - a dictionary that maps an id of a node to the fully qualified name of the class\n",
    "                    \"targets_[n]\" - list of node indices. The first index is the node to which an import is made,\n",
    "                    the second index is the node from which the import is mad (the node the baseline has to predict)\n",
    "                    the following n indices are alternative nodes that the system is presented with and has to\n",
    "                    distinguish from the positive.\n",
    "    \"\"\"\n",
    "    for n in TARGET_SIZES:\n",
    "        graph[\"ed_\" + str(n)] = np.zeros(len(graph[\"targets_\" + str(n)]))\n",
    "        if len(graph[\"targets_\" + str(n)]) == 0:\n",
    "            continue\n",
    "        anchor_str = graph[\"strings\"][graph[\"targets_\" + str(n)][0]]\n",
    "        anchor_str = anchor_str.split('.')[-1]\n",
    "        for i in range(len(graph[\"targets_\" + str(n)])):\n",
    "            node_id = graph[\"targets_\" + str(n)][i]\n",
    "            node_str = graph[\"strings\"][node_id]\n",
    "            node_str = node_str.split('.')[-1]\n",
    "            graph[\"ed_\" + str(n)][i] = levenshtein(anchor_str, node_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (ii) distance between corresponding embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_embedding_distance(graph):\n",
    "    \"\"\"\n",
    "    For each datapoint in the dataset calculate the distance between embeddings of teh two relevant nodes.\n",
    "    Since these embeddings are composed of two parts that encode conceptually different things (see above), \n",
    "    two distances are calculated\n",
    "    :param graph: see docstring for calculate_edit_distance()\n",
    "    \"\"\"\n",
    "    for n in TARGET_SIZES:\n",
    "        graph[\"emb_self_\" + str(n)] = np.zeros(len(graph[\"targets_\" + str(n)]))\n",
    "        graph[\"emb_imp_\" + str(n)] = np.zeros(len(graph[\"targets_\" + str(n)]))\n",
    "        if len(graph[\"targets_\" + str(n)]) == 0:\n",
    "            continue\n",
    "        anchor_emb = graph[\"annotations\"][graph[\"targets_\" + str(n)][0]]\n",
    "        for i in range(len(graph[\"targets_\" + str(n)])):\n",
    "            node_id = graph[\"targets_\" + str(n)][i]\n",
    "            node_emb = graph[\"annotations\"][node_id]\n",
    "            graph[\"emb_self_\" + str(n)][i] = np.sum((anchor_emb[:EMBED_SIZE] - node_emb[:EMBED_SIZE])**2)  \n",
    "            graph[\"emb_imp_\" + str(n)][i] = np.sum((anchor_emb[EMBED_SIZE:] - node_emb[EMBED_SIZE:])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (iii) shortest distance from one node to the other on the graph and (iv) degree of a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_graph(graph):\n",
    "    \"\"\"\n",
    "    Take a graph as described in the docstring for calculate_edit_distance() and return a networkx representation\n",
    "    of that graph\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    for i in range(len(graph[\"strings\"])):\n",
    "        node = i\n",
    "        G.add_node(node)\n",
    "    for edge in graph[\"edges\"]:\n",
    "        node_from, _, node_to = edge\n",
    "        G.add_edge(node_from, node_to)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_graph_features(graph):\n",
    "    \"\"\"\n",
    "    For each datapoint in the dataset calculate the graph-level features for each pair of relevant nodes.\n",
    "    These features are (i) shortest distance from one node to the other on the graph and (ii) degree of a node\n",
    "    :param graph: see docstring for calculate_edit_distance()\n",
    "    \"\"\"\n",
    "    G = nx_graph(graph)\n",
    "    for n in TARGET_SIZES:\n",
    "        graph[\"min_dist_\" + str(n)] = np.zeros(len(graph[\"targets_\" + str(n)]))\n",
    "        graph[\"degree_\" + str(n)] = np.zeros(len(graph[\"targets_\" + str(n)]))\n",
    "        if len(graph[\"targets_\" + str(n)]) == 0:\n",
    "            continue\n",
    "        anchor = graph[\"targets_\" + str(n)][0]\n",
    "        target = graph[\"targets_\" + str(n)][1]\n",
    "        G.remove_edge(anchor, target)\n",
    "        path_lengths = nx.single_source_shortest_path_length(G, anchor)\n",
    "        G.add_edge(anchor, target)\n",
    "        not_reachable = max(path_lengths.values()) + 1\n",
    "        # print(path_lengths, not_reachable)\n",
    "        for i in range(len(graph[\"targets_\" + str(n)])):\n",
    "            node = graph[\"targets_\" + str(n)][i]\n",
    "            graph[\"min_dist_\" + str(n)][i] = path_lengths.get(node, not_reachable)\n",
    "            graph[\"degree_\" + str(n)][i] = G.degree(node)\n",
    "            # print(graph[\"strings\"][anchor].split('.')[-1], \n",
    "            # graph[\"strings\"][node].split('.')[-1], graph[\"features_min_dist_\" + str(n)][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate all the features for the training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90551c7e45434f4aa83cba6087a5f454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2167.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for graph in tqdm(test):\n",
    "    calculate_edit_distance(graph)\n",
    "    calculate_embedding_distance(graph)\n",
    "    calculate_graph_features(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6aed147017b4ffe94c1ccb2313ab41c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19503.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for graph in tqdm(train):\n",
    "    calculate_edit_distance(graph)\n",
    "    calculate_embedding_distance(graph)\n",
    "    calculate_graph_features(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See how good each of the features is for import prediction alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_max_or_min(graph, n, key, ismax=True):\n",
    "    \"\"\"\n",
    "    Given a feature name, a graph, and the number of options to consider (TARGET_SIZE)\n",
    "    select the option that maximizes or minimizes the feature value and\n",
    "    return 1 if the option is the correct prediction and 0 otherwise\n",
    "    :param graph: see docstring for calculate_edit_distance()\n",
    "    :param n:     the number of options to consider. Should be the element of TARGET_SIZES\n",
    "    :param key:   the feature to make the prediction by. Should be a string and element of FEATURES list\n",
    "    ;param ismax: whether to take max or min\n",
    "    \"\"\"\n",
    "    if ismax:\n",
    "        extreme = np.max(graph[key + str(n)][1:])\n",
    "    else:\n",
    "        extreme = np.min(graph[key + str(n)][1:])\n",
    "    if graph[key + str(n)][1] != extreme:\n",
    "        return 0\n",
    "    options = np.where(graph[key + str(n)][1:] == extreme)[0]\n",
    "    if len(options) > 1:\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_baseline(baseline, n):\n",
    "    \"\"\"\n",
    "    Test hoe well a given baseline fares with a given number of options in terms of accuraccy.\n",
    "    Note that accuraccy is obviously dependent on the number of options. The random baseline in always 1/n\n",
    "    :param baseline:a function that takes a graph and n as options\n",
    "    :param n:       number of options to consider\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for graph in test:\n",
    "        if len(graph[\"targets_\" + str(n)]) == 0:\n",
    "            continue\n",
    "        total += 1\n",
    "        correct += baseline(graph, n)\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is the breakdown of how well each feature is for predicting imports on its own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with 1 options:\n",
      "\ted_:\t55.1\n",
      "\temb_self_:\t51.1\n",
      "\temb_imp_:\t47.6\n",
      "\tdegree_:\t72.2\n",
      "\tmin_dist_:\t33.5\n",
      "Testing with 4 options:\n",
      "\ted_:\t27.6\n",
      "\temb_self_:\t26.8\n",
      "\temb_imp_:\t24.7\n",
      "\tdegree_:\t52.1\n",
      "\tmin_dist_:\t11.9\n",
      "Testing with 24 options:\n",
      "\ted_:\t10.3\n",
      "\temb_self_:\t7.7\n",
      "\temb_imp_:\t6.6\n",
      "\tdegree_:\t27.4\n",
      "\tmin_dist_:\t2.5\n",
      "Testing with 124 options:\n",
      "\ted_:\t7.3\n",
      "\temb_self_:\t4.0\n",
      "\temb_imp_:\t2.6\n",
      "\tdegree_:\t16.1\n",
      "\tmin_dist_:\t2.6\n"
     ]
    }
   ],
   "source": [
    "for n in TARGET_SIZES:\n",
    "    print(\"Testing with %d options:\" % n)\n",
    "    for feature in FEATURES:\n",
    "        min_result = test_baseline(lambda x, y: take_max_or_min(x, y, feature, ismax=False), n)\n",
    "        max_result = test_baseline(lambda x, y: take_max_or_min(x, y, feature, ismax=True), n)\n",
    "        print(\"\\t\" + feature + \":\\t\" + str(round(max(min_result, max_result) * 100, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing all feature values before feeding them to different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(dataset):\n",
    "    for n in tqdm(TARGET_SIZES):\n",
    "        for graph in dataset:\n",
    "            if len(graph[\"targets_\" + str(n)]) == 0:\n",
    "                continue\n",
    "            for feature in FEATURES:\n",
    "                max_value = np.max(graph[feature + str(n)][1:])\n",
    "                if max_value != 0:\n",
    "                    graph[feature + str(n)] /= max_value\n",
    "                    graph[feature + str(n)] -= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b98c4ee12d4c57a8f0c28cdc0ea4a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "normalize(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d1f2b96cdf4b6c946227aeee34e71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "normalize(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert all the data in the format that can be easily used with sklearn classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da40458e6fe94b14a003352c7180b3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_y = {}\n",
    "train_X = {}\n",
    "for n in tqdm(TARGET_SIZES):\n",
    "    train_y[n] = []\n",
    "    train_X[n] = []\n",
    "    for graph in train:\n",
    "        if len(graph[\"targets_\" + str(n)]) == 0:\n",
    "            continue\n",
    "        features = np.stack([graph[feature + str(n)] for feature in FEATURES], axis=1)\n",
    "        for i in range(1, n+2):\n",
    "            train_X[n].append(features[i])  \n",
    "        curr_y = np.zeros(n+1)\n",
    "        curr_y[0] = 1\n",
    "        train_y[n] += list(curr_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train random forest and SVM classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "008efea77e2140dbbd6a047452e6167b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classsifiers = {}\n",
    "for n in tqdm(TARGET_SIZES):\n",
    "    classsifiers[n] = RandomForestClassifier(n_estimators = 100, n_jobs=2)\n",
    "    classsifiers[n].fit(train_X[n], train_y[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifierSVM = svm.SVC(probability=True, verbose=True)\n",
    "classifierSVM.fit(train_X[1], train_y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(graph, n, classifier):\n",
    "    \"\"\"\n",
    "    Test a sklearn classifier. This is analagoues to take_max_or_min function above. \n",
    "    The function return 1 if the classifier makes a correct prediction for the given graph and 0 otherwise\n",
    "    \"\"\"\n",
    "    features = np.stack([graph[feature + str(n)] for feature in FEATURES], axis=1)\n",
    "    test_X = []\n",
    "    for i in range(1, n+2):\n",
    "        test_X.append(features[i]) \n",
    "    proba = classifier.predict_proba(test_X)\n",
    "    extreme = np.max(proba, axis=0)[1]\n",
    "    if proba[0][1] != extreme:\n",
    "        return 0\n",
    "    options = np.where(proba[:, 1] == extreme)[0]\n",
    "    if len(options) > 1:\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test random forest and SVM classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with 1 options:\n",
      "Testing with random forest yields:0.755883710198431\n",
      "Testing with 4 options:\n",
      "Testing with random forest yields:0.5435724602792489\n",
      "Testing with 24 options:\n",
      "Testing with random forest yields:0.2568951930654058\n",
      "Testing with 124 options:\n",
      "Testing with random forest yields:0.16117216117216118\n"
     ]
    }
   ],
   "source": [
    "for n in TARGET_SIZES:\n",
    "    print(\"Testing with %d options:\" % n)\n",
    "    print(\"Testing with random forest yields:\" + \n",
    "          str(test_baseline(lambda x, y: test_classifier(x, y, classsifiers[y]), n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with 1 options:\n",
      "Testing with svm yields:0.7641901245962159\n",
      "Testing with 4 options:\n",
      "Testing with svm yields:0.45931632161771785\n",
      "Testing with 24 options:\n",
      "Testing with svm yields:0.136327817178881\n",
      "Testing with 124 options:\n",
      "Testing with svm yields:0.03296703296703297\n"
     ]
    }
   ],
   "source": [
    "for n in TARGET_SIZES:\n",
    "    print(\"Testing with %d options:\" % n)\n",
    "    print(\"Testing with svm yields:\" + \n",
    "          str(test_baseline(lambda x, y: test_classifier(x, y, classifierSVM), n)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "import",
   "language": "python",
   "name": "import"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
