{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook contains code to generate baselines for the import prediction problem that the newural network results could later be compared to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import networkx as nx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different number of negatives a classifier is given. For Target size of 1, the problem becomes a binary\n",
    "# classifiecation problem (one positive, one negative). In other cases, this is a multiclass classification\n",
    "TARGET_SIZES = (1, 4, 24, 124)\n",
    "EMBED_SIZE = 50 # Embedding size used\n",
    "# keys for different features described below\n",
    "FEATURES = (\"ed_\", \"degree_\", \"min_dist_\", \"emb_self_\", \"emb_imp_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = joblib.load(\"../data/graphsTest50\")\n",
    "train = joblib.load(\"../data/graphsTrain50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating various features to be used in baseline prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (i) Edit distance between compilation unit names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from Wikipedia\n",
    "def levenshtein(s1, s2):\n",
    "    \"\"\"\n",
    "    Function to calculate edit distance between to strings. Copied from wikipedia\n",
    "    \"\"\"\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein(s2, s1)\n",
    "\n",
    "    # len(s1) >= len(s2)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1 # j+1 instead of j since previous_row and current_row are one character longer\n",
    "            deletions = current_row[j] + 1       # than s2\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    \n",
    "    return previous_row[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_edit_distance(graph):\n",
    "    \"\"\"\n",
    "    For each datapoint in the dataset calculate the edit distance between relevant pairs of nodes\n",
    "    :param graph:   a dictionary of the following form: \n",
    "                    \"annotations\" - initial node embeddings. These are composed of two parts. The first one\n",
    "                    encodes the class name, the second part record external imports in that class\\compilation unit\n",
    "                    \"edges\"   - a list of tuples of three elements each (source, edge_type, destination)\n",
    "                    \"strings\" - a dictionary that maps an id of a node to the fully qualified name of the class\n",
    "                    \"targets_[n]\" - list of node indices. The first index is the node to which an import is made,\n",
    "                    the second index is the node from which the import is mad (the node the baseline has to predict)\n",
    "                    the following n indices are alternative nodes that the system is presented with and has to\n",
    "                    distinguish from the positive.\n",
    "    \"\"\"\n",
    "    for n in TARGET_SIZES:\n",
    "        graph[\"ed_\" + str(n)] = np.zeros(len(graph[\"targets_\" + str(n)]))\n",
    "        if len(graph[\"targets_\" + str(n)]) == 0:\n",
    "            continue\n",
    "        anchor_str = graph[\"strings\"][graph[\"targets_\" + str(n)][0]]\n",
    "        anchor_str = anchor_str.split('.')[-1]\n",
    "        for i in range(len(graph[\"targets_\" + str(n)])):\n",
    "            node_id = graph[\"targets_\" + str(n)][i]\n",
    "            node_str = graph[\"strings\"][node_id]\n",
    "            node_str = node_str.split('.')[-1]\n",
    "            graph[\"ed_\" + str(n)][i] = levenshtein(anchor_str, node_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (ii) distance between corresponding embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_embedding_distance(graph):\n",
    "    \"\"\"\n",
    "    For each datapoint in the dataset calculate the distance between embeddings of teh two relevant nodes.\n",
    "    Since these embeddings are composed of two parts that encode conceptually different things (see above), \n",
    "    two distances are calculated\n",
    "    :param graph: see docstring for calculate_edit_distance()\n",
    "    \"\"\"\n",
    "    for n in TARGET_SIZES:\n",
    "        graph[\"emb_self_\" + str(n)] = np.zeros(len(graph[\"targets_\" + str(n)]))\n",
    "        graph[\"emb_imp_\" + str(n)] = np.zeros(len(graph[\"targets_\" + str(n)]))\n",
    "        graph[\"emb_full_\" + str(n)] = np.zeros((len(graph[\"targets_\" + str(n)]), EMBED_SIZE * 4))\n",
    "        if len(graph[\"targets_\" + str(n)]) == 0:\n",
    "            continue\n",
    "        anchor_emb = graph[\"annotations\"][graph[\"targets_\" + str(n)][0]]\n",
    "        for i in range(len(graph[\"targets_\" + str(n)])):\n",
    "            node_id = graph[\"targets_\" + str(n)][i]\n",
    "            node_emb = graph[\"annotations\"][node_id]\n",
    "            graph[\"emb_self_\" + str(n)][i] = np.sum((anchor_emb[:EMBED_SIZE] - node_emb[:EMBED_SIZE])**2)  \n",
    "            graph[\"emb_imp_\" + str(n)][i] = np.sum((anchor_emb[EMBED_SIZE:] - node_emb[EMBED_SIZE:])**2)\n",
    "            graph[\"emb_full_\" + str(n)][i] = np.concatenate((anchor_emb, node_emb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (iii) shortest distance from one node to the other on the graph and (iv) degree of a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_graph(graph):\n",
    "    \"\"\"\n",
    "    Take a graph as described in the docstring for calculate_edit_distance() and return a networkx representation\n",
    "    of that graph\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    for i in range(len(graph[\"strings\"])):\n",
    "        node = i\n",
    "        G.add_node(node)\n",
    "    for edge in graph[\"edges\"]:\n",
    "        node_from, _, node_to = edge\n",
    "        G.add_edge(node_from, node_to)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_graph_features(graph):\n",
    "    \"\"\"\n",
    "    For each datapoint in the dataset calculate the graph-level features for each pair of relevant nodes.\n",
    "    These features are (i) shortest distance from one node to the other on the graph and (ii) degree of a node\n",
    "    :param graph: see docstring for calculate_edit_distance()\n",
    "    \"\"\"\n",
    "    G = nx_graph(graph)\n",
    "    for n in TARGET_SIZES:\n",
    "        graph[\"min_dist_\" + str(n)] = np.zeros(len(graph[\"targets_\" + str(n)]))\n",
    "        graph[\"degree_\" + str(n)] = np.zeros(len(graph[\"targets_\" + str(n)]))\n",
    "        if len(graph[\"targets_\" + str(n)]) == 0:\n",
    "            continue\n",
    "        anchor = graph[\"targets_\" + str(n)][0]\n",
    "        target = graph[\"targets_\" + str(n)][1]\n",
    "        G.remove_edge(anchor, target)\n",
    "        path_lengths = nx.single_source_shortest_path_length(G, anchor)\n",
    "        G.add_edge(anchor, target)\n",
    "        not_reachable = max(path_lengths.values()) + 1\n",
    "        # print(path_lengths, not_reachable)\n",
    "        for i in range(len(graph[\"targets_\" + str(n)])):\n",
    "            node = graph[\"targets_\" + str(n)][i]\n",
    "            graph[\"min_dist_\" + str(n)][i] = path_lengths.get(node, not_reachable)\n",
    "            graph[\"degree_\" + str(n)][i] = G.degree(node)\n",
    "            # print(graph[\"strings\"][anchor].split('.')[-1], \n",
    "            # graph[\"strings\"][node].split('.')[-1], graph[\"features_min_dist_\" + str(n)][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate all the features for the training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05ececb30904056b78381d1b0e31268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2167.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for graph in tqdm(test):\n",
    "    calculate_edit_distance(graph)\n",
    "    calculate_embedding_distance(graph)\n",
    "    calculate_graph_features(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b736d2d246f40739884a8fc0b735ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19503.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for graph in tqdm(train):\n",
    "    calculate_edit_distance(graph)\n",
    "    calculate_embedding_distance(graph)\n",
    "    calculate_graph_features(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See how good each of the features is for import prediction alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_max_or_min(graph, n, key, ismax=True):\n",
    "    \"\"\"\n",
    "    Given a feature name, a graph, and the number of options to consider (TARGET_SIZE)\n",
    "    select the option that maximizes or minimizes the feature value and\n",
    "    return 1 if the option is the correct prediction and 0 otherwise\n",
    "    :param graph: see docstring for calculate_edit_distance()\n",
    "    :param n:     the number of options to consider. Should be the element of TARGET_SIZES\n",
    "    :param key:   the feature to make the prediction by. Should be a string and element of FEATURES list\n",
    "    ;param ismax: whether to take max or min\n",
    "    \"\"\"\n",
    "    if ismax:\n",
    "        extreme = np.max(graph[key + str(n)][1:])\n",
    "    else:\n",
    "        extreme = np.min(graph[key + str(n)][1:])\n",
    "    if graph[key + str(n)][1] != extreme:\n",
    "        return 0\n",
    "    options = np.where(graph[key + str(n)][1:] == extreme)[0]\n",
    "    return 1/len(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_baseline(baseline, n):\n",
    "    \"\"\"\n",
    "    Test hoe well a given baseline fares with a given number of options in terms of accuraccy.\n",
    "    Note that accuraccy is obviously dependent on the number of options. The random baseline in always 1/n\n",
    "    :param baseline:a function that takes a graph and n as options\n",
    "    :param n:       number of options to consider\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for graph in test:\n",
    "        if len(graph[\"targets_\" + str(n)]) == 0:\n",
    "            continue\n",
    "        total += 1\n",
    "        correct += baseline(graph, n, total-1)\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is the breakdown of how well each feature is for predicting imports on its own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with 1 options:\n",
      "\ted_:\t61.9\n",
      "\tdegree_:\t74.2\n",
      "\tmin_dist_:\t62.3\n",
      "\temb_self_:\t50.8\n",
      "\temb_imp_:\t50.2\n",
      "Testing with 4 options:\n",
      "\ted_:\t31.4\n",
      "\tdegree_:\t51.8\n",
      "\tmin_dist_:\t31.2\n",
      "\temb_self_:\t25.1\n",
      "\temb_imp_:\t24.4\n",
      "Testing with 24 options:\n",
      "\ted_:\t12.9\n",
      "\tdegree_:\t25.3\n",
      "\tmin_dist_:\t9.1\n",
      "\temb_self_:\t9.3\n",
      "\temb_imp_:\t6.7\n",
      "Testing with 124 options:\n",
      "\ted_:\t6.5\n",
      "\tdegree_:\t9.8\n",
      "\tmin_dist_:\t2.5\n",
      "\temb_self_:\t4.1\n",
      "\temb_imp_:\t1.7\n"
     ]
    }
   ],
   "source": [
    "for n in TARGET_SIZES:\n",
    "    print(\"Testing with %d options:\" % n)\n",
    "    for feature in FEATURES:\n",
    "        min_result = test_baseline(lambda x, y, _: take_max_or_min(x, y, feature, ismax=False), n)\n",
    "        max_result = test_baseline(lambda x, y, _: take_max_or_min(x, y, feature, ismax=True), n)\n",
    "        print(\"\\t\" + feature + \":\\t\" + str(round(max(min_result, max_result) * 100, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert all the data in the format that can be easily used with sklearn classifiers and normalize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_xy_format(n, dataset, func, scaler=None):\n",
    "    y = []\n",
    "    X = []\n",
    "    for graph in dataset:\n",
    "        if len(graph[\"targets_\" + str(n)]) == 0:\n",
    "            continue\n",
    "        features = func(graph)\n",
    "        if scaler:\n",
    "            features[1:] = scaler.fit_transform(features[1:])\n",
    "        for i in range(1, n+2):\n",
    "            X.append(features[i])  \n",
    "        curr_y = np.zeros(n+1)\n",
    "        curr_y[0] = 1\n",
    "        y += list(curr_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc67c888da6a47a6a7034da2f9b2b1e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_y = {}\n",
    "train_X = {}\n",
    "test_y = {}\n",
    "test_X = {}\n",
    "for n in tqdm(TARGET_SIZES):\n",
    "    func = lambda x: np.stack([x[feature + str(n)] for feature in FEATURES], axis=1)\n",
    "    scaler = StandardScaler(copy=False, with_mean=True, with_std=True)\n",
    "    train_X[n], train_y[n] = convert_to_xy_format(n, train, func, scaler=scaler)\n",
    "    test_X[n], test_y[n] = convert_to_xy_format(n, test, func, scaler=scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test random forest and SVM classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classsifiers = {}\n",
    "for n in tqdm(TARGET_SIZES):\n",
    "    classsifiers[n] = RandomForestClassifier(n_estimators = 100, n_jobs=2)\n",
    "    classsifiers[n].fit(train_X[n], train_y[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classsifiersSVMs = {}\n",
    "for n in tqdm(TARGET_SIZES[:1]):\n",
    "    classsifiersSVMs[n] = svm.SVC(probability=True, verbose=True)\n",
    "    classsifiersSVMs[n].fit(train_X[n], train_y[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(X, classifier):\n",
    "    \"\"\"\n",
    "    Test a sklearn classifier. This is analagoues to take_max_or_min function above. \n",
    "    The function return 1 if the classifier makes a correct prediction for the given graph and 0 otherwise\n",
    "    \"\"\"\n",
    "    proba = classifier.predict_proba(X)\n",
    "    extreme = np.max(proba, axis=0)[1]\n",
    "    if proba[0][1] != extreme:\n",
    "        return 0\n",
    "    options = np.where(proba[:, 1] == extreme)[0]\n",
    "    return 1 / len(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in TARGET_SIZES:\n",
    "    print(\"Testing with %d options:\" % n)\n",
    "    print(\"Testing with random forest yields:\" + \n",
    "          str(test_baseline(lambda g, n, i: test_classifier(test_X[n][(n+1)*i:(n+1)*(i+1)], classsifiers[n]), n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in TARGET_SIZES:\n",
    "    print(\"Testing with %d options:\" % n)\n",
    "    print(\"Testing with svm yields:\" + \n",
    "          str(test_baseline(lambda g, n, i: test_classifier(test_X[n][(n+1)*i:(n+1)*(i+1)], classsifiersSVMs[1]), n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e66b49d86f344a683292444b5d419ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embed_train_y = {}\n",
    "embed_train_X = {}\n",
    "embed_test_y = {}\n",
    "embed_test_X = {}\n",
    "for n in tqdm(TARGET_SIZES):\n",
    "    func = lambda x: x[\"emb_full_\" + str(n)]\n",
    "    embed_train_X[n], embed_train_y[n] = convert_to_xy_format(n, train, func)\n",
    "    embed_test_X[n], embed_test_y[n] = convert_to_xy_format(n, test, func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as tt\n",
    "from torch import nn\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \"\"\"Simple One layer Autoencoder\"\"\"\n",
    "    def __init__(self, in_size):\n",
    "        super(FeedForward, self).__init__()\n",
    "        midway = int(in_size**0.5)\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_size, midway),\n",
    "            nn.Linear(midway, int(midway/2)),\n",
    "            nn.Linear(int(midway/2), 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_X, n, binary_acc=False):\n",
    "    id = 0\n",
    "    accurate = 0\n",
    "    model.eval()\n",
    "    for id in range(int(len(test_X)/(n+1))):\n",
    "        batch_X = tt.tensor(test_X[id * (n+1):(id + 1) * (n+1)]).float().cuda()\n",
    "        id += n\n",
    "        \n",
    "        output = model(batch_X).cpu().detach().numpy()\n",
    "        if binary_acc:\n",
    "            accurate += len(np.where(output<output[0])[0])/n\n",
    "        else:\n",
    "            extreme = np.max(output, axis=0)\n",
    "            if output[0] != extreme:\n",
    "                continue\n",
    "            options = np.where(output == extreme)[0]\n",
    "            accurate += 1 / len(options)\n",
    "    return accurate / (len(test_X) / (n+1))\n",
    "    print(full_train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_X, train_y, n, patience=3, batch_size=int(1e5)):\n",
    "    valid_X = train_X[:int(len(train_X)/10)]\n",
    "    train_X = train_X[int(len(train_X)/10):]\n",
    "    train_y = train_y[int(len(train_y)/10):]\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = tt.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    model.cuda()\n",
    "    \n",
    "    best_acc = -1\n",
    "    best_state_dict = None\n",
    "    patience_left = patience\n",
    "    epoch = -1\n",
    "    bar = tqdm()\n",
    "    \n",
    "    while patience_left > 0:\n",
    "        model.train()\n",
    "        p = np.random.permutation(len(train_X))\n",
    "        train_X=train_X[p]\n",
    "        train_y=train_y[p]\n",
    "        epoch += 1\n",
    "        total_loss = 0\n",
    "        id = 0\n",
    "        while id < len(train_X):\n",
    "            if id + batch_size <=len(train_X):\n",
    "                batch_X = tt.tensor(train_X[id:id+batch_size]).float().cuda()\n",
    "                batch_y = tt.tensor(train_y[id:id+batch_size]).float().cuda()\n",
    "            else:\n",
    "                batch_X = tt.tensor(train_X[id:]).float().cuda()\n",
    "                batch_y = tt.tensor(train_y[id:]).float().cuda()\n",
    "            id += batch_size\n",
    "            output = model(batch_X)\n",
    "            loss = criterion(output, batch_y)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        total_loss *= batch_size/len(train_X)  # to get the mean\n",
    "        acc = evaluate_model(model, valid_X, n, binary_acc=True)\n",
    "        \n",
    "        if best_acc == -1 or best_acc < acc:\n",
    "            best_acc = acc\n",
    "            patience_left = patience\n",
    "            best_state_dict = copy.deepcopy(model.state_dict())\n",
    "        else:\n",
    "            patience_left -= 1\n",
    "        bar.set_description(\"Epochs: %d, Loss: %f, Acc: %f\" %(epoch, total_loss, acc))\n",
    "        bar.update(1)\n",
    "    \n",
    "    model.load_state_dict(best_state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in TARGET_SIZES:\n",
    "    print(\"Testing with %d options:\" % n)\n",
    "    model = FeedForward(EMBED_SIZE * 4)\n",
    "    train_model(model, embed_train_X[n], embed_train_y[n], n, patience=3, batch_size=int(1e4))\n",
    "    print(\"Testing with ffnn on embeddings yields:\" + str(evaluate_model(model, embed_test_X[n], n)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in TARGET_SIZES:\n",
    "    train_X[n] = np.concatenate((train_X[n], embed_train_X[n]), axis=1)\n",
    "    test_X[n] = np.concatenate((test_X[n], embed_test_X[n]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with 1 options:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f8ad5c19584225a4f3ebf5dc991090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with ffnn on embeddings yields:0.7741116751269036\n",
      "Testing with 4 options:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8784a31758c145e2b41f6118a13fec9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with ffnn on embeddings yields:0.5402189433603046\n",
      "Testing with 24 options:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9790de6b98784daa9c96028bcb7775e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with ffnn on embeddings yields:0.27631578947368424\n",
      "Testing with 124 options:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b62cc34bc4e458a9b6d1ae691169d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with ffnn on embeddings yields:0.08713692946058091\n"
     ]
    }
   ],
   "source": [
    "for n in TARGET_SIZES:\n",
    "    print(\"Testing with %d options:\" % n)\n",
    "    model = FeedForward(EMBED_SIZE * 4 + len(FEATURES))\n",
    "    train_model(model, train_X[n], train_y[n], n, patience=3, batch_size=int(1e4))\n",
    "    print(\"Testing with ffnn on embeddings yields:\" + str(evaluate_model(model, test_X[n], n)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "import",
   "language": "python",
   "name": "import"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
